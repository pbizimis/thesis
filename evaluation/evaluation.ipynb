{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Eval.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rW-kfFs484h8"
      },
      "source": [
        "# Set-Up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpL9JEM2ME3P"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMoYAs7qNSVs"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1JqYEoYMwQ_"
      },
      "source": [
        "!pip install click requests tqdm pyspng ninja imageio-ffmpeg==0.4.3 torch==1.7.1+cu110 torchvision==0.8.2+cu110 torchaudio===0.7.2 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OX8nFlo3NRgM"
      },
      "source": [
        "!git clone https://github.com/NVlabs/stylegan2-ada-pytorch.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bl-9TvrmNUoF"
      },
      "source": [
        "%cd stylegan2-ada-pytorch/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9F3e1Nse88sf"
      },
      "source": [
        "# Negative Truncation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dz9HZW5Xrel-"
      },
      "source": [
        "!python generate.py --outdir=out --trunc=-1 --seeds=3190102548 --network=/content/drive/MyDrive/Training/best_pkl/final_256.pkl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyTVQPbN9CZG"
      },
      "source": [
        "# Define 5 Random Seeds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhYT_jP2Cb8r"
      },
      "source": [
        "import random\n",
        "\n",
        "latents = []\n",
        "for i in range(5):\n",
        "  latents.append(random.randint(0,2**32-1))\n",
        "\n",
        "print(latents)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDMcq7cd9Khf"
      },
      "source": [
        "# Save 5 Images of Each Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2Y51_UmNV-S"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import legacy\n",
        "import PIL.Image\n",
        "import dnnlib\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "eval_folder_path = \"/content/drive/MyDrive/Philip/P~U/SS~2021/Assests/Samples\"\n",
        "model_folder_path = \"/content/drive/MyDrive/Training/best_pkl\"\n",
        "\n",
        "truncation_value = 1\n",
        "device = torch.device('cuda')\n",
        "\n",
        "for model in os.listdir(model_folder_path):\n",
        "\n",
        "  model_path = os.path.join(model_folder_path, model)\n",
        "  eval_path = os.path.join(eval_folder_path, os.path.splitext(model)[0])\n",
        "\n",
        "  try:\n",
        "    shutil.rmtree(eval_path)\n",
        "  except:\n",
        "    print(\"Missing folder created\")\n",
        "  os.makedirs(eval_path, exist_ok=True)\n",
        "\n",
        "  with dnnlib.util.open_url(model_path) as f:\n",
        "    G = legacy.load_network_pkl(f)['G_ema'].to(device)\n",
        "\n",
        "  for l in latents:\n",
        "    z = torch.from_numpy(np.random.RandomState(l).randn(1, G.z_dim)).to(device)\n",
        "    label = torch.zeros([1, G.c_dim], device=device)\n",
        "\n",
        "    img = G(z, label, truncation_psi=truncation_value, noise_mode=\"const\")\n",
        "    img = (img.permute(0, 2, 3, 1) * 127.5 + 128).clamp(0, 255).to(torch.uint8)\n",
        "    PIL.Image.fromarray(img[0].cpu().numpy(), 'RGB').save(f'{eval_path}/seed{l}.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nabYTeE09aDV"
      },
      "source": [
        "# Save The Average Image of Each Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMPOw3XdR2gs"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import legacy\n",
        "import PIL.Image\n",
        "import dnnlib\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "eval_folder_path = \"/content/drive/MyDrive/Philip/P~U/SS~2021/Assests/SamplesTrunc0\"\n",
        "model_folder_path = \"/content/drive/MyDrive/Training/best_pkl\"\n",
        "\n",
        "truncation_value = 0\n",
        "device = torch.device('cuda')\n",
        "\n",
        "for model in os.listdir(model_folder_path):\n",
        "\n",
        "  model_path = os.path.join(model_folder_path, model)\n",
        "  eval_path = os.path.join(eval_folder_path, os.path.splitext(model)[0])\n",
        "\n",
        "  try:\n",
        "    shutil.rmtree(eval_path)\n",
        "  except:\n",
        "    print(\"Missing folder created\")\n",
        "  os.makedirs(eval_path, exist_ok=True)\n",
        "\n",
        "  with dnnlib.util.open_url(model_path) as f:\n",
        "    G = legacy.load_network_pkl(f)['G_ema'].to(device)\n",
        "\n",
        "  l = random.randint(0,2**32-1)\n",
        "  z = torch.from_numpy(np.random.RandomState(l).randn(1, G.z_dim)).to(device)\n",
        "  label = torch.zeros([1, G.c_dim], device=device)\n",
        "\n",
        "  img = G(z, label, truncation_psi=truncation_value, noise_mode=\"const\")\n",
        "  img = (img.permute(0, 2, 3, 1) * 127.5 + 128).clamp(0, 255).to(torch.uint8)\n",
        "  PIL.Image.fromarray(img[0].cpu().numpy(), 'RGB').save(f'{eval_path}/seed{l}.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNiL8v8L9ghb"
      },
      "source": [
        "# Save 50 Images of One Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLCODkjClYUg"
      },
      "source": [
        "# Save 50 images of one model\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import legacy\n",
        "import PIL.Image\n",
        "import dnnlib\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "latents = []\n",
        "for i in range(500):\n",
        "  latents.append(random.randint(0,2**32-1))\n",
        "\n",
        "print(latents)\n",
        "\n",
        "eval_folder_path = \"/content/drive/MyDrive/Philip/P~U/SS~2021/Assests/256_final_samples\"\n",
        "model_folder_path = \"/content/drive/MyDrive/Training/best_pkl/final_256.pkl\"\n",
        "\n",
        "truncation_value = 1\n",
        "device = torch.device('cuda')\n",
        "\n",
        "try:\n",
        "  shutil.rmtree(eval_folder_path)\n",
        "except:\n",
        "  print(\"Missing folder created\")\n",
        "os.makedirs(eval_folder_path, exist_ok=True)\n",
        "\n",
        "with dnnlib.util.open_url(model_folder_path) as f:\n",
        "  G = legacy.load_network_pkl(f)['G_ema'].to(device)\n",
        "\n",
        "for l in latents:\n",
        "  z = torch.from_numpy(np.random.RandomState(l).randn(1, G.z_dim)).to(device)\n",
        "  label = torch.zeros([1, G.c_dim], device=device)\n",
        "\n",
        "  img = G(z, label, truncation_psi=truncation_value, noise_mode=\"const\")\n",
        "  img = (img.permute(0, 2, 3, 1) * 127.5 + 128).clamp(0, 255).to(torch.uint8)\n",
        "  PIL.Image.fromarray(img[0].cpu().numpy(), 'RGB').save(f'{eval_folder_path}/seed{l}.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTwakySr9je7"
      },
      "source": [
        "# Style-Mixing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQpAComoNiGU"
      },
      "source": [
        "# styles 0-13, 0-1 2-5 6-13\n",
        "!python style_mixing.py --styles=6-13 --outdir=/content/drive/MyDrive/Philip/P~U/SS~2021/Assests/6-13 --rows=4264001345,4229487283,3697211462,3432756122,3310702129,3190102548 --cols=4264001345,4229487283,3697211462,3432756122,3310702129,3190102548 --network=/content/drive/MyDrive/Training/best_pkl/final_256.pkl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNATkhxN9mFr"
      },
      "source": [
        "# Create FID Development Plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvNPe2x1d37w"
      },
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import pandas as pd\n",
        "from matplotlib.ticker import FormatStrFormatter\n",
        "import math\n",
        "\n",
        "path_to_model_dir = \"/content/drive/MyDrive/Training/\"\n",
        "model_folder_list = os.listdir(path_to_model_dir)\n",
        "\n",
        "fid_values_all_models = {}\n",
        "\n",
        "for model_folder in model_folder_list:\n",
        "  if \"training\" in model_folder:\n",
        "    model_folder_path = os.path.join(path_to_model_dir, model_folder)\n",
        "    run_folder_list = sorted(os.listdir(model_folder_path))\n",
        "\n",
        "    y = []\n",
        "\n",
        "    for j, run_folder in enumerate(run_folder_list):\n",
        "      skip = True\n",
        "\n",
        "      if j == 0:\n",
        "        skip = False\n",
        "\n",
        "      run_folder_path = os.path.join(model_folder_path, run_folder)\n",
        "      with open(os.path.join(run_folder_path,\"metric-fid50k_full.jsonl\"), 'r') as json_file:\n",
        "        json_list = list(json_file)\n",
        "        for i, json_line in enumerate(json_list):\n",
        "          if i == 0 and skip:\n",
        "            continue\n",
        "          fid_value = json.loads(json_line)[\"results\"][\"fid50k_full\"]\n",
        "          y.append(fid_value)\n",
        "\n",
        "    fid_values_all_models[model_folder] = y\n",
        "\n",
        "x = np.linspace(0,12.6,64)[:-1]\n",
        "\n",
        "dataframe = pd.DataFrame(dict([(k,pd.Series(v)) for k,v in fid_values_all_models.items()]))\n",
        "\n",
        "sns.set()\n",
        "fig, ax = plt.subplots(figsize=(9,5))\n",
        "\n",
        "# sns.lineplot(x = x, y = dataframe.loc[:, \"training_sets_gauto\"], ax=ax, label=r\"$\\gamma = 0,1024$\")\n",
        "# sns.lineplot(x = x, y = dataframe.loc[:, \"training_sets_g5\"], ax=ax, label=r\"$\\gamma = 5$\")\n",
        "# sns.lineplot(x = x, y = dataframe.loc[:, \"training_sets_g10\"], ax=ax, label=r\"$\\gamma = 10$\")\n",
        "# sns.lineplot(x = x, y = dataframe.loc[:, \"training_sets_g15\"], ax=ax, label=r\"$\\gamma = 15$\")\n",
        "# sns.lineplot(x = x, y = dataframe.loc[:, \"training_sets_g100\"], ax=ax, label=r\"$\\gamma = 100$\")\n",
        "# sns.lineplot(x = x, y = dataframe.loc[:, \"training_sets_g1000\"], ax=ax, label=r\"$\\gamma = 1000$\")\n",
        "\n",
        "# sns.lineplot(x = x, y = dataframe.loc[:, \"training_sets_gauto\"], ax=ax, label=\"ADA, no x-flips\")\n",
        "# sns.lineplot(x = x, y = dataframe.loc[:, \"training_sets_gautonoada\"], ax=ax, label=\"no ADA, no x-flips\")\n",
        "# sns.lineplot(x = x, y = dataframe.loc[:, \"training_sets_gautomirror\"], ax=ax, label=\"ADA, x-flips\")\n",
        "\n",
        "sns.lineplot(x = x, y = dataframe.loc[:, \"training_sets_gauto\"], ax=ax, label=r\"31k, $128\\times128$\")\n",
        "sns.lineplot(x = x, y = dataframe.loc[:, \"training_sets_256_13k\"], ax=ax, label=r\"13k, $256\\times256$\")\n",
        "sns.lineplot(x = x, y = dataframe.loc[:, \"training_sets_128_10k\"], ax=ax, label=r\"11k, $128\\times128$\")\n",
        "sns.lineplot(x = x, y = dataframe.loc[:, \"training_sets_128_1.9k\"], ax=ax, label=r\"2k, $128\\times128$\")\n",
        "\n",
        "ax.axvline(10.6, color=\"b\", linewidth=1)\n",
        "ax.set_xlabel(\"Training progress (number of real images shown to the discriminator)\", labelpad=10, fontsize=14)\n",
        "ax.set_ylabel(\"FID\", labelpad=5, fontsize=14)\n",
        "\n",
        "######################################\n",
        "def forward(x):\n",
        "    return np.log(2+x)\n",
        "\n",
        "\n",
        "def inverse(x):\n",
        "    return np.exp(x)-2\n",
        "\n",
        "ax.set_xscale('function', functions=(forward, inverse))\n",
        "###############################################\n",
        "\n",
        "ax.set_yscale(\"log\")\n",
        "ax.set_yticks([10,15,20,25,30,50,100,200,300])\n",
        "ax.get_yaxis().set_major_formatter(matplotlib.ticker.ScalarFormatter())\n",
        "###############################################\n",
        "plt.xlim(xmin=0)\n",
        "ax.xaxis.set_major_formatter(FormatStrFormatter('%dM'))\n",
        "handles, labels = ax.get_legend_handles_labels()\n",
        "ax.legend(handles, labels, fontsize=14, loc=\"upper right\")\n",
        "plt.show()\n",
        "fig.savefig('fid_figure_ds.png', bbox_inches='tight', pad_inches=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pmrHVTC-BXA"
      },
      "source": [
        "# Find The Snapshot With The Lowest FID of Each Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qECDqJUnktgT"
      },
      "source": [
        "lowest = [100, \"\", 0]\n",
        "\n",
        "for k,v in fid_values_all_models.items():\n",
        "  for i, fid in enumerate(v):\n",
        "    if fid < lowest[0]:\n",
        "      lowest[0] = fid\n",
        "      lowest[1] = k\n",
        "      lowest[2] = i\n",
        "\n",
        "print(lowest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W26P_WmL-J2D"
      },
      "source": [
        "# Project Image to Latent Space"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dg85ZK361ntR"
      },
      "source": [
        "# projection of apple.com\n",
        "!python projector.py --save-video=False --outdir=/content/drive/MyDrive/Philip/P~U/SS~2021/Assests/Projection/apple10k --target=/content/drive/MyDrive/Training/good_images/apple_com.png --network=/content/drive/MyDrive/Training/best_pkl/10827images_fid14.41.pkl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SncmYC4T-Msr"
      },
      "source": [
        "# Style-Mix of Projected Image With Samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cclbX-gIGKe"
      },
      "source": [
        "import os\n",
        "import re\n",
        "from typing import List\n",
        "\n",
        "import click\n",
        "import dnnlib\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "import torch\n",
        "\n",
        "import legacy\n",
        "\n",
        "def generate_style_mix(\n",
        "    network_pkl: str,\n",
        "    row_seeds: List[int],\n",
        "    col_seeds: List[int],\n",
        "    col_styles: List[int],\n",
        "    truncation_psi: float,\n",
        "    noise_mode: str,\n",
        "    outdir: str,\n",
        "    proj_w: str\n",
        "):\n",
        "\n",
        "  print('Loading networks from \"%s\"...' % network_pkl)\n",
        "  device = torch.device('cuda')\n",
        "  with dnnlib.util.open_url(network_pkl) as f:\n",
        "      G = legacy.load_network_pkl(f)['G_ema'].to(device) # type: ignore\n",
        "\n",
        "  os.makedirs(outdir, exist_ok=True)\n",
        "\n",
        "  ws = np.load(proj_w)['w']\n",
        "  ws = torch.tensor(ws, device=device)\n",
        "\n",
        "  print('Generating W vectors...')\n",
        "  all_seeds = list(set(row_seeds + col_seeds))\n",
        "  all_z = np.stack([np.random.RandomState(seed).randn(G.z_dim) for seed in all_seeds])\n",
        "  all_w = G.mapping(torch.from_numpy(all_z).to(device), None)\n",
        "\n",
        "  w_avg = G.mapping.w_avg\n",
        "  all_w = w_avg + (all_w - w_avg) * truncation_psi\n",
        "\n",
        "  for w in ws:\n",
        "    all_w = torch.cat((all_w, w.unsqueeze(0)),0)\n",
        "\n",
        "  all_seeds.append(\"proj_w\")\n",
        "  row_seeds.append(\"proj_w\")\n",
        "  col_seeds.append(\"proj_w\")\n",
        "\n",
        "  w_dict = {seed: w for seed, w in zip(all_seeds, list(all_w))}\n",
        "\n",
        "\n",
        "  print('Generating images...')\n",
        "  all_images = G.synthesis(all_w, noise_mode=noise_mode)\n",
        "  all_images = (all_images.permute(0, 2, 3, 1) * 127.5 + 128).clamp(0, 255).to(torch.uint8).cpu().numpy()\n",
        "  image_dict = {(seed, seed): image for seed, image in zip(all_seeds, list(all_images))}\n",
        "\n",
        "  print('Generating style-mixed images...')\n",
        "  for row_seed in row_seeds:\n",
        "      for col_seed in col_seeds:\n",
        "          w = w_dict[row_seed].clone()\n",
        "          w[col_styles] = w_dict[col_seed][col_styles]\n",
        "          image = G.synthesis(w[np.newaxis], noise_mode=noise_mode)\n",
        "          image = (image.permute(0, 2, 3, 1) * 127.5 + 128).clamp(0, 255).to(torch.uint8)\n",
        "          image_dict[(row_seed, col_seed)] = image[0].cpu().numpy()\n",
        "\n",
        "  print('Saving images...')\n",
        "  os.makedirs(outdir, exist_ok=True)\n",
        "  for (row_seed, col_seed), image in image_dict.items():\n",
        "      PIL.Image.fromarray(image, 'RGB').save(f'{outdir}/{row_seed}-{col_seed}.png')\n",
        "\n",
        "  print('Saving image grid...')\n",
        "  W = G.img_resolution\n",
        "  H = G.img_resolution\n",
        "  canvas = PIL.Image.new('RGB', (W * (len(col_seeds) + 1), H * (len(row_seeds) + 1)), 'black')\n",
        "  for row_idx, row_seed in enumerate([0] + row_seeds):\n",
        "      for col_idx, col_seed in enumerate([0] + col_seeds):\n",
        "          if row_idx == 0 and col_idx == 0:\n",
        "              continue\n",
        "          key = (row_seed, col_seed)\n",
        "          if row_idx == 0:\n",
        "              key = (col_seed, col_seed)\n",
        "          if col_idx == 0:\n",
        "              key = (row_seed, row_seed)\n",
        "          canvas.paste(PIL.Image.fromarray(image_dict[key], 'RGB'), (W * col_idx, H * row_idx))\n",
        "  canvas.save(f'{outdir}/grid.png')\n",
        "\n",
        "generate_style_mix(\n",
        "  network_pkl = \"/content/drive/MyDrive/Training/best_pkl/final_256.pkl\",\n",
        "  row_seeds = [3432756122,3310702129],\n",
        "  col_seeds = [3432756122,3310702129],\n",
        "  col_styles = [2,3,4,5],\n",
        "  truncation_psi = 1,\n",
        "  noise_mode = \"const\",\n",
        "  outdir = \"/content/drive/MyDrive/Philip/P~U/SS~2021/Assests/Projection/style_mix\",\n",
        "  proj_w = \"/content/drive/MyDrive/Philip/P~U/SS~2021/Assests/Projection/applefinal/projected_w.npz\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNVKfW98Depc"
      },
      "source": [
        "# Closed-Form Factorization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwL5uQzpJGT9"
      },
      "source": [
        "# Closed Form Factorization\n",
        "!git clone https://github.com/pbizimis/stylegan2-ada-pytorch.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49g0Zd63DbRc"
      },
      "source": [
        "%cd stylegan2-ada-pytorch/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrZwxuQACcFl"
      },
      "source": [
        "!python closed_form_factorization.py --ckpt /content/drive/MyDrive/Training/best_pkl/final_256.pkl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9kej3UKEfqG"
      },
      "source": [
        "!python apply_factor.py -i=152 --truncation=1 --degree=20 --seeds=4264001345,4229487283,3697211462,3432756122,3310702129,3190102548 --ckpt  /content/drive/MyDrive/Training/best_pkl/final_256.pkl factor.pt --no-video --output=/content/drive/MyDrive/Philip/P~U/SS~2021/Assests/CCF"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}